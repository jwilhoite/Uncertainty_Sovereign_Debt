{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "760a354a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import argparse, os\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.init import kaiming_uniform_\n",
    "from torch.optim.lr_scheduler import LambdaLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2323f61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "DEVICE = torch.device(os.getenv('OP_DEVICE', 'cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "DTYPE  = torch.float64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1e72e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85fab134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "#  Hard‑wired optimiser hyper‑parameters\n",
    "# -----------------------------------------------------------------------------\n",
    "learn_initial = 0.0001\n",
    "learn_middle = 0.000001\n",
    "learn_final = 1e-7\n",
    "\n",
    "layers = [50,50,50]\n",
    "\n",
    "epochs_initial = 30\n",
    "epochs_middle = epochs_initial + 10\n",
    "epochs_total = epochs_middle + 10\n",
    "\n",
    "weight = 0.7\n",
    "neg_weight = 10.0\n",
    "batch_size = 128\n",
    "\n",
    "seed = 33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40016a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14a9fa37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "#  Hard‑wired model parameters\n",
    "# -----------------------------------------------------------------------------\n",
    "crra = 5.0\n",
    "beta = 0.96\n",
    "alpha = 0.5\n",
    "\n",
    "psi = 7.08\n",
    "pi_star = 1.0484\n",
    "\n",
    "rho_y = 0.8118\n",
    "eta = 0.0347\n",
    "sigma_y = eta / np.sqrt(1.0 - (rho_y ** 2.0))\n",
    "\n",
    "mu = 0.0\n",
    "y_ubnd = mu + 3.0 * sigma_y\n",
    "y_lbnd = mu - 3.0 * sigma_y\n",
    "\n",
    "b_star_ubnd = 0.3\n",
    "b_star_lbnd = -0.1\n",
    "\n",
    "b_tilde_ubnd = 0.3\n",
    "b_tilde_lbnd = -0.1\n",
    "\n",
    "kappa = 40.0\n",
    "\n",
    "r = 0.04\n",
    "R = np.exp(r)\n",
    "delta = 0.757\n",
    "\n",
    "qstar = 1.0 / (R - delta)\n",
    "\n",
    "EPS = 1e-12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99101124",
   "metadata": {},
   "outputs": [],
   "source": [
    "#n_int sets the number of nodes in the Gauss-Hermite quadrature used to approximate expectations\n",
    "n_int = 19\n",
    "\n",
    "x_int_norm, w_int = np.polynomial.hermite.hermgauss(n_int)\n",
    "w_int = w_int/np.sqrt(np.pi)\n",
    "x_int_norm = x_int_norm * np.sqrt(2)\n",
    "\n",
    "w_int = torch.from_numpy(w_int).to(DEVICE)\n",
    "x_int_norm = torch.from_numpy(x_int_norm).to(DEVICE)\n",
    "\n",
    "innovation_i = x_int_norm.view(1, n_int, 1)\n",
    "weight_i = w_int.view(1, n_int, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1d552dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_gpu_memory():\n",
    "    \n",
    "    num_gpus = torch.cuda.device_count()\n",
    "    for i in range(num_gpus):\n",
    "        # Get the current GPU's total memory and memory allocated\n",
    "        total_memory = torch.cuda.get_device_properties(i).total_memory\n",
    "        allocated_memory = torch.cuda.memory_allocated(i)\n",
    "        cached_memory = torch.cuda.memory_reserved(i)\n",
    "\n",
    "        # Convert bytes to GB for easier interpretation\n",
    "        total_memory_gb = total_memory / (1024 ** 3)\n",
    "        allocated_memory_gb = allocated_memory / (1024 ** 3)\n",
    "        cached_memory_gb = cached_memory / (1024 ** 3)\n",
    "        free_memory_gb = total_memory_gb - (allocated_memory_gb + cached_memory_gb)\n",
    "\n",
    "        print(f\"GPU {i}:\")\n",
    "        print(f\"  Total Memory: {total_memory_gb:.2f} GB\")\n",
    "        print(f\"  Allocated Memory: {allocated_memory_gb:.2f} GB\")\n",
    "        print(f\"  Cached Memory: {cached_memory_gb:.2f} GB\")\n",
    "        print(f\"  Free Memory (approx.): {free_memory_gb:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1df6d614",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class NN_pi(nn.Module):\n",
    "    def __init__(self, in_szs, out_szs, layers):\n",
    "        super().__init__()\n",
    "\n",
    "        layerlist = []\n",
    "        n_in = in_szs\n",
    "        \n",
    "        for i in layers:\n",
    "            kaiming_uniform_(nn.Linear(n_in, i).weight, nonlinearity='leaky_relu')\n",
    "            layerlist.append(nn.Linear(n_in, i))\n",
    "            layerlist.append(nn.LeakyReLU())\n",
    "            n_in = i\n",
    "        \n",
    "        layerlist.append(nn.Linear(layers[-1], out_szs))\n",
    "        layerlist.append(nn.Sigmoid())\n",
    "        \n",
    "        self.layers = nn.Sequential(*layerlist)\n",
    "                \n",
    "    def forward(self, x):\n",
    "        \n",
    "        pred = self.layers(x)\n",
    "        \n",
    "        pred = pred * (1.1 - 1.0) + 1.0\n",
    "                    \n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09523290",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class NN_foreign(nn.Module):\n",
    "    def __init__(self, in_szs, out_szs, layers):\n",
    "        super().__init__()\n",
    "\n",
    "        layerlist = []\n",
    "        n_in = in_szs\n",
    "        \n",
    "        for i in layers:\n",
    "            kaiming_uniform_(nn.Linear(n_in, i).weight, nonlinearity='leaky_relu')\n",
    "            layerlist.append(nn.Linear(n_in, i))\n",
    "            layerlist.append(nn.LeakyReLU())\n",
    "            n_in = i\n",
    "        \n",
    "        layerlist.append(nn.Linear(layers[-1], out_szs))\n",
    "        layerlist.append(nn.Identity())\n",
    "        \n",
    "        self.layers = nn.Sequential(*layerlist)\n",
    "                \n",
    "    def forward(self, x):\n",
    "        \n",
    "        pred = self.layers(x)\n",
    "                    \n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa9c7038",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class NN_local(nn.Module):\n",
    "    def __init__(self, in_szs, out_szs, layers):\n",
    "        super().__init__()\n",
    "\n",
    "        layerlist = []\n",
    "        n_in = in_szs\n",
    "        \n",
    "        for i in layers:\n",
    "            kaiming_uniform_(nn.Linear(n_in, i).weight, nonlinearity='leaky_relu')\n",
    "            layerlist.append(nn.Linear(n_in, i))\n",
    "            layerlist.append(nn.LeakyReLU())\n",
    "            n_in = i\n",
    "        \n",
    "        layerlist.append(nn.Linear(layers[-1], out_szs))\n",
    "        layerlist.append(nn.Identity())\n",
    "        \n",
    "        self.layers = nn.Sequential(*layerlist)\n",
    "                \n",
    "    def forward(self, x):\n",
    "        \n",
    "        pred = self.layers(x)\n",
    "                    \n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "729dbc6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class NN_val(nn.Module):\n",
    "    def __init__(self, in_szs, out_szs, layers):\n",
    "        super().__init__()\n",
    "\n",
    "        layerlist = []\n",
    "        n_in = in_szs\n",
    "        \n",
    "        for i in layers:\n",
    "            kaiming_uniform_(nn.Linear(n_in, i).weight, nonlinearity='leaky_relu')\n",
    "            layerlist.append(nn.Linear(n_in, i))\n",
    "            layerlist.append(nn.LeakyReLU())\n",
    "            n_in = i\n",
    "        \n",
    "        layerlist.append(nn.Linear(layers[-1], out_szs))\n",
    "        layerlist.append(nn.Identity())\n",
    "        \n",
    "        self.layers = nn.Sequential(*layerlist)\n",
    "                \n",
    "    def forward(self, x):\n",
    "        \n",
    "        pred = self.layers(x)\n",
    "                    \n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c0e37f34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class NN_qtilde(nn.Module):\n",
    "    def __init__(self, in_szs, out_szs, layers):\n",
    "        super().__init__()\n",
    "\n",
    "        layerlist = []\n",
    "        n_in = in_szs\n",
    "        \n",
    "        for i in layers:\n",
    "            kaiming_uniform_(nn.Linear(n_in, i).weight, nonlinearity='leaky_relu')\n",
    "            layerlist.append(nn.Linear(n_in, i))\n",
    "            layerlist.append(nn.LeakyReLU())\n",
    "            n_in = i\n",
    "        \n",
    "        layerlist.append(nn.Linear(layers[-1], out_szs))\n",
    "        layerlist.append(nn.Sigmoid())\n",
    "        \n",
    "        self.layers = nn.Sequential(*layerlist)\n",
    "                \n",
    "    def forward(self, x):\n",
    "        \n",
    "        pred = self.layers(x)\n",
    "        \n",
    "        pred = pred * 10.0\n",
    "                    \n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0591300f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class NN_q(nn.Module):\n",
    "    def __init__(self, in_szs, out_szs, layers):\n",
    "        super().__init__()\n",
    "\n",
    "        layerlist = []\n",
    "        n_in = in_szs\n",
    "        \n",
    "        for i in layers:\n",
    "            kaiming_uniform_(nn.Linear(n_in, i).weight, nonlinearity='leaky_relu')\n",
    "            layerlist.append(nn.Linear(n_in, i))\n",
    "            layerlist.append(nn.LeakyReLU())\n",
    "            n_in = i\n",
    "        \n",
    "        layerlist.append(nn.Linear(layers[-1], out_szs))\n",
    "        layerlist.append(nn.Softplus())\n",
    "        \n",
    "        self.layers = nn.Sequential(*layerlist)\n",
    "                \n",
    "    def forward(self, x):\n",
    "        \n",
    "        pred = self.layers(x)\n",
    "                                    \n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "31a575f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_error(X, nn_pi, nn_foreign, nn_local, nn_val, nn_qtilde, nn_q):\n",
    "        \n",
    "    n_data = X.shape[0]\n",
    "    \n",
    "    yt = X[:, 0:1]\n",
    "    bstar = X[:, 1:2]\n",
    "    btilde = X[:, 2:3]\n",
    "        \n",
    "    pi = nn_pi(X)\n",
    "    bstar_prime = nn_foreign(X)\n",
    "    btilde_prime = nn_local(X)\n",
    "    val = nn_val(X)\n",
    "        \n",
    "    exp_val_prime = torch.zeros((n_data, 1), device=DEVICE, dtype=torch.float64)\n",
    "    exp_qtilde_inside = torch.zeros((n_data, 1), device=DEVICE, dtype=torch.float64)\n",
    "    \n",
    "    exp_dval_prime_dbstar_prime = torch.zeros((n_data, 1), device=DEVICE, dtype=torch.float64)\n",
    "    exp_dval_prime_dbtilde_prime = torch.zeros((n_data, 1), device=DEVICE, dtype=torch.float64)\n",
    "    \n",
    "    exp_dqtilde_dbstar_prime_inside = torch.zeros((n_data, 1), device=DEVICE, dtype=torch.float64)\n",
    "    exp_dqtilde_dbtilde_prime_inside = torch.zeros((n_data, 1), device=DEVICE, dtype=torch.float64)\n",
    "    \n",
    "    # ------------------------------------------------------------------\n",
    "    # Compute expectation terms using vectorized code\n",
    "    # ------------------------------------------------------------------\n",
    "    #Below B represents the batch size\n",
    "    yt_b = yt[:,None]     # (B,1,1)\n",
    "    \n",
    "    m = torch.exp(-r - kappa * innovation_i * eta - 0.5 * (kappa ** 2.0) * (eta ** 2.0))\n",
    "    \n",
    "    yt_prime = torch.exp(rho_y * torch.log(yt_b) + innovation_i * eta)\n",
    "    \n",
    "    yt_prime = yt_prime.expand(-1, n_int, -1) # (B, n_int, 1)\n",
    "    m = m.expand(-1, n_int, -1)\n",
    "    \n",
    "    bstar_p = bstar_prime.unsqueeze(1)\n",
    "    btilde_p = btilde_prime.unsqueeze(1)\n",
    "    \n",
    "    bstar_p = bstar_p.expand(-1, n_int, -1)\n",
    "    btilde_p = btilde_p.expand(-1, n_int, -1)\n",
    "    \n",
    "    X_prime = torch.cat((yt_prime, bstar_p, btilde_p), dim = -1)\n",
    "    X_prime_flat = X_prime.reshape(-1, 3)  # (B*n_int , 3)\n",
    "    \n",
    "    val_prime, qtilde_inside, dval_prime_dbstar_prime, dval_prime_dbtilde_prime, dqtilde_dbstar_prime_inside, dqtilde_dbtilde_prime_inside = get_exp_prime(X_prime_flat, nn_pi, nn_foreign, nn_local, nn_val, nn_qtilde, nn_q)\n",
    "\n",
    "    val_prime = val_prime.view(n_data, n_int, 1)\n",
    "    qtilde_inside = qtilde_inside.view(n_data, n_int, 1)\n",
    "    \n",
    "    dval_prime_dbstar_prime = dval_prime_dbstar_prime.view(n_data, n_int, 1)\n",
    "    dval_prime_dbtilde_prime = dval_prime_dbtilde_prime.view(n_data, n_int, 1)\n",
    "    \n",
    "    dqtilde_dbstar_prime_inside = dqtilde_dbstar_prime_inside.view(n_data, n_int, 1)\n",
    "    dqtilde_dbtilde_prime_inside = dqtilde_dbtilde_prime_inside.view(n_data, n_int, 1)\n",
    "    \n",
    "    exp_val_prime = (weight_i * val_prime).sum(1)\n",
    "    exp_qtilde_inside = (weight_i * m * qtilde_inside).sum(1)\n",
    "    \n",
    "    exp_dval_prime_dbstar_prime = (weight_i * dval_prime_dbstar_prime).sum(1)\n",
    "    exp_dval_prime_dbtilde_prime = (weight_i * dval_prime_dbtilde_prime).sum(1)\n",
    "    \n",
    "    exp_dqtilde_dbstar_prime_inside = (weight_i * m * dqtilde_dbstar_prime_inside).sum(1)\n",
    "    exp_dqtilde_dbtilde_prime_inside = (weight_i * m * dqtilde_dbtilde_prime_inside).sum(1)\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # Use expectations to construct error terms\n",
    "    # ------------------------------------------------------------------\n",
    "        \n",
    "    qtilde = exp_qtilde_inside\n",
    "    dqtilde_dbstar_prime = exp_dqtilde_dbstar_prime_inside\n",
    "    dqtilde_dbtilde_prime = exp_dqtilde_dbtilde_prime_inside\n",
    "    \n",
    "    ct_discriminant = ((btilde / pi) ** 2.0) - 4.0 * (bstar - qstar * (bstar_prime - delta * bstar) - qtilde * (btilde_prime - delta * (btilde / pi)) - yt)\n",
    "    ct_discriminant_clamped = torch.clamp(ct_discriminant, min = EPS)\n",
    "    numerator = (-btilde / pi) + (ct_discriminant_clamped ** 0.5)\n",
    "    ct = 0.25 * (numerator ** 2.0)\n",
    "    \n",
    "    zeta = (1.0 / pi) * (ct ** (1.0 - alpha))\n",
    "    zeta_one = ct ** (1.0 - alpha)\n",
    "    dzeta_dpi = -(1.0 / (pi ** 2.0)) * (ct ** (1.0 - alpha))\n",
    "    dzeta_dct = (1.0 - alpha) * (1.0 / pi) * (ct ** -alpha)\n",
    "    \n",
    "    c = ct ** alpha\n",
    "    lambda_ct_numerator = (1.0 - beta) * (c ** -crra) * alpha * (ct ** (alpha - 1.0))\n",
    "    lambda_ct_denominator = 1.0 + dzeta_dct * btilde\n",
    "    lambda_ct = lambda_ct_numerator / lambda_ct_denominator\n",
    "    \n",
    "    lambda_pi_numerator = (1.0 - beta) * psi * (pi - pi_star)\n",
    "    lambda_pi_denominator = (btilde / (pi ** 2.0)) * (ct ** (1.0 - alpha)) + delta * (btilde / (pi ** 2.0)) * qtilde\n",
    "    lambda_pi = lambda_pi_numerator / lambda_pi_denominator\n",
    "    \n",
    "    q = (1.0 / zeta_one) * qtilde\n",
    "\n",
    "    qtilde_pred = nn_qtilde(X)\n",
    "    q_pred = nn_q(X)\n",
    "    \n",
    "    qtilde_detached = qtilde.detach()\n",
    "    q_detached = q.detach()\n",
    "    \n",
    "    err_qtilde = qtilde_detached - qtilde_pred\n",
    "    \n",
    "    err_q = q_detached - q_pred\n",
    "    \n",
    "    err_val = (1.0 - beta) * (((c ** (1.0 - crra)) / (1.0 - crra)) - (psi / 2.0) * ((pi - pi_star) ** 2.0)) + beta * exp_val_prime - val\n",
    "    \n",
    "    errREE_c_pi = lambda_ct - lambda_pi\n",
    "    \n",
    "    errREE_bstar = lambda_ct * (qstar + dqtilde_dbstar_prime * (btilde_prime - delta * (btilde / pi))) + beta * exp_dval_prime_dbstar_prime\n",
    "    \n",
    "    errREE_btilde = lambda_ct * (qtilde + dqtilde_dbtilde_prime * (btilde_prime - delta * (btilde / pi))) + beta * exp_dval_prime_dbtilde_prime\n",
    "    \n",
    "    err_discriminant = torch.clamp(-ct_discriminant, min = 0.0)\n",
    "    \n",
    "    err_numerator = torch.clamp(-numerator, min = 0.0)\n",
    "    \n",
    "    return err_val, errREE_c_pi, errREE_bstar, errREE_btilde, err_qtilde, err_q, err_discriminant, err_numerator\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a913dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_exp_prime(X_prime, nn_pi, nn_foreign, nn_local, nn_val, nn_qtilde, nn_q):\n",
    "        \n",
    "    n_data = X_prime.shape[0]\n",
    "    \n",
    "    yt_prime = X_prime[:, 0:1]\n",
    "    bstar_prime = X_prime[:, 1:2]\n",
    "    btilde_prime = X_prime[:, 2:3]\n",
    "    \n",
    "    pi_prime = nn_pi(X_prime)\n",
    "    bstar_prime_next = nn_foreign(X_prime)\n",
    "    btilde_prime_next = nn_local(X_prime)\n",
    "    val_prime = nn_val(X_prime)\n",
    "        \n",
    "    qtilde_prime = nn_qtilde(X_prime)\n",
    "    q_prime = nn_q(X_prime)\n",
    "    \n",
    "    ct_discriminant_prime = ((btilde_prime / pi_prime) ** 2.0) - 4.0 * (bstar_prime - qstar * (bstar_prime_next - delta * bstar_prime) - qtilde_prime * (btilde_prime_next - delta * (btilde_prime / pi_prime)) - yt_prime)\n",
    "    ct_discriminant_prime_clamped = torch.clamp(ct_discriminant_prime, min = EPS)\n",
    "    ct_prime = 0.25 * (((-btilde_prime / pi_prime) + (ct_discriminant_prime_clamped ** 0.5)) ** 2.0)\n",
    "    \n",
    "    zeta_prime = (1.0 / pi_prime) * (ct_prime ** (1.0 - alpha))\n",
    "    dzeta_prime_dpi_prime = -(1.0 / (pi_prime ** 2.0)) * (ct_prime ** (1.0 - alpha))\n",
    "    dzeta_prime_dct_prime = (1.0 - alpha) * (1.0 / pi_prime) * (ct_prime ** -alpha)\n",
    "    \n",
    "    qtilde_inside = zeta_prime * (1.0 + delta * q_prime)\n",
    "    \n",
    "    c_prime = ct_prime ** alpha\n",
    "    lambda_ct_prime_numerator = (1.0 - beta) * (c_prime ** -crra) * alpha * (ct_prime ** (alpha - 1.0))\n",
    "    lambda_ct_prime_denominator = 1.0 + dzeta_prime_dct_prime * btilde_prime\n",
    "    lambda_ct_prime = lambda_ct_prime_numerator / lambda_ct_prime_denominator\n",
    "    \n",
    "    dval_prime_dbstar_prime = -lambda_ct_prime * (1.0 + qstar * delta)\n",
    "    dval_prime_dbtilde_prime = -lambda_ct_prime * (zeta_prime + qtilde_prime * delta * (1.0 / pi_prime))\n",
    "    \n",
    "    (dct_prime_dbstar_prime, dct_prime_dbtilde_prime, dpi_prime_dbstar_prime, \n",
    "     dpi_prime_dbtilde_prime, dq_prime_dbstar_prime, dq_prime_dbtilde_prime) = get_autograd_derivative(X_prime, nn_pi, nn_foreign, nn_local, nn_qtilde, nn_q)\n",
    "    \n",
    "    dqtilde_dbstar_prime_inside = (dzeta_prime_dpi_prime * dpi_prime_dbstar_prime + dzeta_prime_dct_prime * dct_prime_dbstar_prime) * (1.0 + delta * q_prime) + zeta_prime * delta * dq_prime_dbstar_prime\n",
    "    dqtilde_dbtilde_prime_inside = (dzeta_prime_dpi_prime * dpi_prime_dbtilde_prime + dzeta_prime_dct_prime * dct_prime_dbtilde_prime) * (1.0 + delta * q_prime) + zeta_prime * delta * dq_prime_dbtilde_prime\n",
    "    \n",
    "    return val_prime, qtilde_inside, dval_prime_dbstar_prime, dval_prime_dbtilde_prime, dqtilde_dbstar_prime_inside, dqtilde_dbtilde_prime_inside\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8bee3274",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_autograd_derivative(X_prime, nn_pi, nn_foreign, nn_local, nn_qtilde, nn_q):\n",
    "        \n",
    "    X_prime_auto = X_prime.detach().clone().requires_grad_(True)\n",
    "    \n",
    "    yt_prime_auto = X_prime_auto[:, 0:1]\n",
    "    bstar_prime_auto = X_prime_auto[:, 1:2]\n",
    "    btilde_prime_auto = X_prime_auto[:, 2:3]\n",
    "    \n",
    "    pi_prime_auto = nn_pi(X_prime_auto)\n",
    "    bstar_prime_next_auto = nn_foreign(X_prime_auto)\n",
    "    btilde_prime_next_auto = nn_local(X_prime_auto)\n",
    "    qtilde_prime_auto = nn_qtilde(X_prime_auto)\n",
    "    q_prime_auto = nn_q(X_prime_auto)\n",
    "    \n",
    "    ct_discriminant_prime_auto = ((btilde_prime_auto / pi_prime_auto) ** 2.0) - 4.0 * (bstar_prime_auto - qstar * (bstar_prime_next_auto - delta * bstar_prime_auto) - qtilde_prime_auto * (btilde_prime_next_auto - delta * (btilde_prime_auto / pi_prime_auto)) - yt_prime_auto)\n",
    "    ct_discriminant_prime_auto_clamped = torch.clamp(ct_discriminant_prime_auto, min = EPS)\n",
    "    numerator_prime_auto = (-btilde_prime_auto / pi_prime_auto) + torch.sqrt(ct_discriminant_prime_auto_clamped)\n",
    "    ct_prime_auto = 0.25 * (numerator_prime_auto ** 2.0)\n",
    "    \n",
    "    ct_grads = torch.autograd.grad(\n",
    "    outputs=ct_prime_auto,                      # shape (n_data, 1)\n",
    "    inputs=X_prime_auto,             # shape (n_data, 4)\n",
    "    grad_outputs=torch.ones_like(ct_prime_auto),  # each row's derivative\n",
    "    create_graph=True,)[0]\n",
    "    \n",
    "    #Compute the derivatives of ct_prime\n",
    "    dct_prime_dbstar_prime = ct_grads[:, 1:2]\n",
    "    dct_prime_dbtilde_prime = ct_grads[:, 2:3]\n",
    "    \n",
    "    pi_grads = torch.autograd.grad(\n",
    "    outputs=pi_prime_auto,                      # shape (n_data, 1)\n",
    "    inputs=X_prime_auto,             # shape (n_data, 3)\n",
    "    grad_outputs=torch.ones_like(pi_prime_auto),  # each row's derivative\n",
    "    create_graph=True,)[0]\n",
    "    \n",
    "    #Compute the derivatives of pi_prime\n",
    "    dpi_prime_dbstar_prime = pi_grads[:, 1:2]\n",
    "    dpi_prime_dbtilde_prime = pi_grads[:, 2:3]                   # shape (n_data, 1)\n",
    "    \n",
    "    q_grads = torch.autograd.grad(\n",
    "    outputs=q_prime_auto,                      # shape (n_data, 1)\n",
    "    inputs=X_prime_auto,             # shape (n_data, 3)\n",
    "    grad_outputs=torch.ones_like(q_prime_auto),  # each row's derivative\n",
    "    create_graph=True,)[0]\n",
    "    \n",
    "    #Compute the derivatives of q_prime\n",
    "    dq_prime_dbstar_prime = q_grads[:, 1:2]\n",
    "    dq_prime_dbtilde_prime = q_grads[:, 2:3]\n",
    "\n",
    "    \n",
    "    return dct_prime_dbstar_prime, dct_prime_dbtilde_prime, dpi_prime_dbstar_prime, dpi_prime_dbtilde_prime, dq_prime_dbstar_prime, dq_prime_dbtilde_prime\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "43b1f69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(X, nn_pi, nn_foreign, nn_local, nn_val, nn_qtilde, nn_q):\n",
    "        \n",
    "    w_neg = neg_weight\n",
    "    w_val = weight\n",
    "    w_ERR = (1.0 -  w_val) / 5.0\n",
    "    \n",
    "    err_val, errREE_c_pi, errREE_bstar, errREE_btilde, err_qtilde, err_q, err_discriminant, err_numerator = compute_error(X, nn_pi, nn_foreign, nn_local, nn_val, nn_qtilde, nn_q)\n",
    "        \n",
    "    loss = w_ERR * torch.mean(errREE_c_pi ** 2) + w_ERR * torch.mean(errREE_bstar ** 2) + w_ERR * torch.mean(errREE_btilde ** 2) + w_ERR * torch.mean(err_qtilde ** 2) + w_ERR * torch.mean(err_q ** 2) + w_val * torch.mean(err_val ** 2) + w_neg * torch.mean(err_discriminant ** 2) + w_neg * torch.mean(err_numerator ** 2) \n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "34a01226",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(num_points):\n",
    "    \n",
    "    yt = torch.FloatTensor(num_points, 1).uniform_(y_lbnd, y_ubnd)\n",
    "    yt = torch.exp(yt)\n",
    "    bstar = torch.FloatTensor(num_points, 1).uniform_(b_star_lbnd, b_star_ubnd)\n",
    "    btilde = torch.FloatTensor(num_points, 1).uniform_(b_tilde_lbnd, b_tilde_ubnd)\n",
    "    \n",
    "    data = torch.cat((yt, bstar, btilde), dim = 1)\n",
    "    data = data.to(device=DEVICE, dtype=torch.float64).to(DEVICE)\n",
    "    \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ef2fd407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss is 122717.8708385917\n",
      "Epoch 20 loss is 1.0152205848674115e+25\n",
      "Epoch 40 loss is 16441355.624562748\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# Instantiate six neural nets\n",
    "# ------------------------------------------------------------------\n",
    "model_pi = NN_pi(3, 1, layers)\n",
    "model_pi = model_pi.to(device=DEVICE, dtype=torch.float64).to(DEVICE)\n",
    "\n",
    "model_foreign = NN_foreign(3, 1, layers)\n",
    "model_foreign = model_foreign.to(device=DEVICE, dtype=torch.float64).to(DEVICE)\n",
    "\n",
    "model_local = NN_local(3, 1, layers)\n",
    "model_local = model_local.to(device=DEVICE, dtype=torch.float64).to(DEVICE)\n",
    "\n",
    "model_val = NN_val(3, 1, layers)\n",
    "model_val = model_val.to(device=DEVICE, dtype=torch.float64).to(DEVICE)\n",
    "\n",
    "model_qtilde = NN_qtilde(3, 1, layers)\n",
    "model_qtilde = model_qtilde.to(device=DEVICE, dtype=torch.float64).to(DEVICE)\n",
    "\n",
    "model_q = NN_q(3, 1, layers)\n",
    "model_q = model_q.to(device=DEVICE, dtype=torch.float64).to(DEVICE)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Set up optimisers and schedulers\n",
    "# ------------------------------------------------------------------\n",
    "optimizer_pi = torch.optim.AdamW(model_pi.parameters(), lr = learn_initial)\n",
    "optimizer_foreign = torch.optim.AdamW(model_foreign.parameters(), lr = learn_initial)\n",
    "optimizer_local = torch.optim.AdamW(model_local.parameters(), lr = learn_initial)\n",
    "optimizer_val = torch.optim.AdamW(model_val.parameters(), lr = learn_initial)\n",
    "optimizer_qtilde = torch.optim.AdamW(model_qtilde.parameters(), lr = learn_initial)\n",
    "optimizer_q = torch.optim.AdamW(model_q.parameters(), lr = learn_initial)\n",
    "\n",
    "# One LR scheduler shared across all nets (piece‑wise constant ratio)\n",
    "def lr_lambda(epoch):\n",
    "    if   epoch < epochs_initial:               \n",
    "        return 1.0\n",
    "    elif epoch < epochs_middle:      \n",
    "        return learn_middle / learn_initial\n",
    "    else:\n",
    "        return learn_final / learn_initial\n",
    "\n",
    "scheduler_pi = LambdaLR(optimizer_pi, lr_lambda = lr_lambda)\n",
    "scheduler_foreign = LambdaLR(optimizer_foreign, lr_lambda = lr_lambda)\n",
    "scheduler_local = LambdaLR(optimizer_local, lr_lambda = lr_lambda)\n",
    "scheduler_val = LambdaLR(optimizer_val, lr_lambda = lr_lambda)\n",
    "scheduler_qtilde = LambdaLR(optimizer_qtilde, lr_lambda = lr_lambda)\n",
    "scheduler_q = LambdaLR(optimizer_q, lr_lambda = lr_lambda)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Training loop \n",
    "# ------------------------------------------------------------------\n",
    "for i in range(epochs_total):\n",
    "\n",
    "    optimizer_pi.zero_grad()\n",
    "    optimizer_foreign.zero_grad()\n",
    "    optimizer_local.zero_grad()\n",
    "    optimizer_val.zero_grad()\n",
    "    optimizer_qtilde.zero_grad()\n",
    "    optimizer_q.zero_grad()\n",
    "\n",
    "    data = get_data(batch_size)\n",
    "\n",
    "    loss = compute_loss(data, model_pi, model_foreign, model_local, model_val, model_qtilde, model_q)\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer_pi.step()\n",
    "    optimizer_foreign.step()\n",
    "    optimizer_local.step()\n",
    "    optimizer_val.step()\n",
    "    optimizer_qtilde.step()\n",
    "    optimizer_q.step()\n",
    "\n",
    "    scheduler_pi.step()\n",
    "    scheduler_foreign.step()\n",
    "    scheduler_local.step()\n",
    "    scheduler_val.step()\n",
    "    scheduler_qtilde.step()\n",
    "    scheduler_q.step()\n",
    "\n",
    "    if i%20 == 0:\n",
    "        print(f'Epoch {i} loss is {loss}')\n",
    "\n",
    "    if i%1000 == 0:\n",
    "        print_gpu_memory()\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Checkpoint models\n",
    "# ------------------------------------------------------------------\n",
    "base = Path(path or \".\").expanduser().resolve()\n",
    "out = base / \"pickle\"\n",
    "out.mkdir(parents=True, exist_ok=True)\n",
    "tag = (f\"kappa{kappa}\")\n",
    "\n",
    "torch.save(model_pi.state_dict(),        out / f\"{tag}_Model_pi.pt\")\n",
    "torch.save(model_foreign.state_dict(),   out / f\"{tag}_Model_foreign.pt\")\n",
    "torch.save(model_local.state_dict(),     out / f\"{tag}_Model_local.pt\")\n",
    "torch.save(model_val.state_dict(),       out / f\"{tag}_Model_val.pt\")\n",
    "torch.save(model_qtilde.state_dict(),    out / f\"{tag}_Model_qtilde.pt\")\n",
    "torch.save(model_q.state_dict(),         out / f\"{tag}_Model_q.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c630adab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "enviro_dis",
   "language": "python",
   "name": "enviro_dis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
