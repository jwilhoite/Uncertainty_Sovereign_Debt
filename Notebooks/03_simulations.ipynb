{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "719954ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Script for simulating data from model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7f5faef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "87167508",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import json\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.filters.hp_filter import hpfilter\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.init import kaiming_uniform_\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af76206b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(os.getenv('OP_DEVICE', 'cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "DTYPE  = torch.float64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2de5032b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "weight = 0.7\n",
    "neg_weight = 10.0\n",
    "batch_size = 128\n",
    "\n",
    "layers = [50, 50, 50]\n",
    "seed = 33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6703709f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(seed)            \n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)    \n",
    "    torch.cuda.manual_seed_all(seed)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "769a61af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "#  Hardâ€‘wired model parameters\n",
    "# -----------------------------------------------------------------------------\n",
    "crra = 5.0\n",
    "beta = 0.9\n",
    "alpha = 0.5\n",
    "\n",
    "psi = 7.08\n",
    "pi_star = 1.0484\n",
    "\n",
    "rho_y = 0.8118\n",
    "eta = 0.0347\n",
    "sigma_y = eta/np.sqrt(1.0 - (rho_y ** 2.0))\n",
    "\n",
    "mu = 0.0\n",
    "y_ubnd = mu + 3.0 * sigma_y\n",
    "y_lbnd = mu - 3.0 * sigma_y\n",
    "\n",
    "b_star_ubnd = 0.3\n",
    "b_star_lbnd = -0.1\n",
    "\n",
    "b_tilde_ubnd = 0.3\n",
    "b_tilde_lbnd = -0.1\n",
    "\n",
    "kappa = 40.0\n",
    "\n",
    "r = 0.039\n",
    "R = np.exp(r)\n",
    "delta = 0.757\n",
    "\n",
    "qstar = 1.0 / (R - delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a4fee418",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = ''\n",
    "base_path = f'{path}/pickle/kappa{kappa}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e7c0fce4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_int = 19\n",
    "\n",
    "x_int_norm, w_int = np.polynomial.hermite.hermgauss(n_int)\n",
    "w_int = w_int/np.sqrt(np.pi)\n",
    "x_int_norm = x_int_norm * np.sqrt(2)\n",
    "\n",
    "w_int = torch.from_numpy(w_int).to(DEVICE)\n",
    "x_int_norm = torch.from_numpy(x_int_norm).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "802bdb89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class NN_pi(nn.Module):\n",
    "    def __init__(self, in_szs, out_szs, layers):\n",
    "        super().__init__()\n",
    "\n",
    "        layerlist = []\n",
    "        n_in = in_szs\n",
    "        \n",
    "        for i in layers:\n",
    "            kaiming_uniform_(nn.Linear(n_in, i).weight, nonlinearity='leaky_relu')\n",
    "            layerlist.append(nn.Linear(n_in, i))\n",
    "            layerlist.append(nn.LeakyReLU())\n",
    "            n_in = i\n",
    "        \n",
    "        layerlist.append(nn.Linear(layers[-1], out_szs))\n",
    "        layerlist.append(nn.Sigmoid())\n",
    "        \n",
    "        self.layers = nn.Sequential(*layerlist)\n",
    "                \n",
    "    def forward(self, x):\n",
    "        \n",
    "        pred = self.layers(x)\n",
    "        \n",
    "        pred = pred * (1.1 - 1.0) + 1.0\n",
    "                    \n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b6665364",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class NN_foreign(nn.Module):\n",
    "    def __init__(self, in_szs, out_szs, layers):\n",
    "        super().__init__()\n",
    "\n",
    "        layerlist = []\n",
    "        n_in = in_szs\n",
    "        \n",
    "        for i in layers:\n",
    "            kaiming_uniform_(nn.Linear(n_in, i).weight, nonlinearity='leaky_relu')\n",
    "            layerlist.append(nn.Linear(n_in, i))\n",
    "            layerlist.append(nn.LeakyReLU())\n",
    "            n_in = i\n",
    "        \n",
    "        layerlist.append(nn.Linear(layers[-1], out_szs))\n",
    "        layerlist.append(nn.Identity())\n",
    "        \n",
    "        self.layers = nn.Sequential(*layerlist)\n",
    "                \n",
    "    def forward(self, x):\n",
    "        \n",
    "        pred = self.layers(x)\n",
    "                    \n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f06dc8ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class NN_local(nn.Module):\n",
    "    def __init__(self, in_szs, out_szs, layers):\n",
    "        super().__init__()\n",
    "\n",
    "        layerlist = []\n",
    "        n_in = in_szs\n",
    "        \n",
    "        for i in layers:\n",
    "            kaiming_uniform_(nn.Linear(n_in, i).weight, nonlinearity='leaky_relu')\n",
    "            layerlist.append(nn.Linear(n_in, i))\n",
    "            layerlist.append(nn.LeakyReLU())\n",
    "            n_in = i\n",
    "        \n",
    "        layerlist.append(nn.Linear(layers[-1], out_szs))\n",
    "        layerlist.append(nn.Identity())\n",
    "        \n",
    "        self.layers = nn.Sequential(*layerlist)\n",
    "                \n",
    "    def forward(self, x):\n",
    "        \n",
    "        pred = self.layers(x)\n",
    "                    \n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "06b91bc6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class NN_val(nn.Module):\n",
    "    def __init__(self, in_szs, out_szs, layers):\n",
    "        super().__init__()\n",
    "\n",
    "        layerlist = []\n",
    "        n_in = in_szs\n",
    "        \n",
    "        for i in layers:\n",
    "            kaiming_uniform_(nn.Linear(n_in, i).weight, nonlinearity='leaky_relu')\n",
    "            layerlist.append(nn.Linear(n_in, i))\n",
    "            layerlist.append(nn.LeakyReLU())\n",
    "            n_in = i\n",
    "        \n",
    "        layerlist.append(nn.Linear(layers[-1], out_szs))\n",
    "        layerlist.append(nn.Identity())\n",
    "        \n",
    "        self.layers = nn.Sequential(*layerlist)\n",
    "                \n",
    "    def forward(self, x):\n",
    "        \n",
    "        pred = self.layers(x)\n",
    "                    \n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0d111279",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class NN_qtilde(nn.Module):\n",
    "    def __init__(self, in_szs, out_szs, layers):\n",
    "        super().__init__()\n",
    "\n",
    "        layerlist = []\n",
    "        n_in = in_szs\n",
    "        \n",
    "        for i in layers:\n",
    "            kaiming_uniform_(nn.Linear(n_in, i).weight, nonlinearity='leaky_relu')\n",
    "            layerlist.append(nn.Linear(n_in, i))\n",
    "            layerlist.append(nn.LeakyReLU())\n",
    "            n_in = i\n",
    "        \n",
    "        layerlist.append(nn.Linear(layers[-1], out_szs))\n",
    "        layerlist.append(nn.Sigmoid())\n",
    "        \n",
    "        self.layers = nn.Sequential(*layerlist)\n",
    "                \n",
    "    def forward(self, x):\n",
    "        \n",
    "        pred = self.layers(x)\n",
    "        \n",
    "        pred = pred * 10.0\n",
    "                    \n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fd5fb6e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class NN_q(nn.Module):\n",
    "    def __init__(self, in_szs, out_szs, layers):\n",
    "        super().__init__()\n",
    "\n",
    "        layerlist = []\n",
    "        n_in = in_szs\n",
    "        \n",
    "        for i in layers:\n",
    "            kaiming_uniform_(nn.Linear(n_in, i).weight, nonlinearity='leaky_relu')\n",
    "            layerlist.append(nn.Linear(n_in, i))\n",
    "            layerlist.append(nn.LeakyReLU())\n",
    "            n_in = i\n",
    "        \n",
    "        layerlist.append(nn.Linear(layers[-1], out_szs))\n",
    "        layerlist.append(nn.Softplus())\n",
    "        \n",
    "        self.layers = nn.Sequential(*layerlist)\n",
    "                \n",
    "    def forward(self, x):\n",
    "        \n",
    "        pred = self.layers(x)\n",
    "                                    \n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dc1086fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NN_pi(\n",
       "  (layers): Sequential(\n",
       "    (0): Linear(in_features=3, out_features=50, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
       "    (3): LeakyReLU(negative_slope=0.01)\n",
       "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
       "    (5): LeakyReLU(negative_slope=0.01)\n",
       "    (6): Linear(in_features=50, out_features=1, bias=True)\n",
       "    (7): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model_pi = NN_pi(3, 1, layers)\n",
    "new_model_pi.load_state_dict(torch.load(f'{base_path}_Model_pi.pt', map_location=DEVICE))\n",
    "new_model_pi = new_model_pi.to(dtype = torch.float64).to(DEVICE)\n",
    "new_model_pi.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bbda1412",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NN_foreign(\n",
       "  (layers): Sequential(\n",
       "    (0): Linear(in_features=3, out_features=50, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
       "    (3): LeakyReLU(negative_slope=0.01)\n",
       "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
       "    (5): LeakyReLU(negative_slope=0.01)\n",
       "    (6): Linear(in_features=50, out_features=1, bias=True)\n",
       "    (7): Identity()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model_foreign = NN_foreign(3, 1, layers)\n",
    "new_model_foreign.load_state_dict(torch.load(f'{base_path}_Model_foreign.pt', map_location=DEVICE))\n",
    "new_model_foreign = new_model_foreign.to(dtype = torch.float64).to(DEVICE)\n",
    "new_model_foreign.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5a299d6c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NN_local(\n",
       "  (layers): Sequential(\n",
       "    (0): Linear(in_features=3, out_features=50, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
       "    (3): LeakyReLU(negative_slope=0.01)\n",
       "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
       "    (5): LeakyReLU(negative_slope=0.01)\n",
       "    (6): Linear(in_features=50, out_features=1, bias=True)\n",
       "    (7): Identity()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model_local = NN_local(3, 1, layers)\n",
    "new_model_local.load_state_dict(torch.load(f'{base_path}_Model_local.pt', map_location=DEVICE))\n",
    "new_model_local = new_model_local.to(dtype = torch.float64).to(DEVICE)\n",
    "new_model_local.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "005a50b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NN_val(\n",
       "  (layers): Sequential(\n",
       "    (0): Linear(in_features=3, out_features=50, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
       "    (3): LeakyReLU(negative_slope=0.01)\n",
       "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
       "    (5): LeakyReLU(negative_slope=0.01)\n",
       "    (6): Linear(in_features=50, out_features=1, bias=True)\n",
       "    (7): Identity()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model_val = NN_val(3, 1, layers)\n",
    "new_model_val.load_state_dict(torch.load(f'{base_path}_Model_val.pt', map_location=DEVICE))\n",
    "new_model_val = new_model_val.to(dtype = torch.float64).to(DEVICE)\n",
    "new_model_val.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cdae3dea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NN_qtilde(\n",
       "  (layers): Sequential(\n",
       "    (0): Linear(in_features=3, out_features=50, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
       "    (3): LeakyReLU(negative_slope=0.01)\n",
       "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
       "    (5): LeakyReLU(negative_slope=0.01)\n",
       "    (6): Linear(in_features=50, out_features=1, bias=True)\n",
       "    (7): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model_qtilde = NN_qtilde(3, 1, layers)\n",
    "new_model_qtilde.load_state_dict(torch.load(f'{base_path}_Model_qtilde.pt', map_location=DEVICE))\n",
    "new_model_qtilde = new_model_qtilde.to(dtype = torch.float64).to(DEVICE)\n",
    "new_model_qtilde.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d790ec09",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NN_q(\n",
       "  (layers): Sequential(\n",
       "    (0): Linear(in_features=3, out_features=50, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
       "    (3): LeakyReLU(negative_slope=0.01)\n",
       "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
       "    (5): LeakyReLU(negative_slope=0.01)\n",
       "    (6): Linear(in_features=50, out_features=1, bias=True)\n",
       "    (7): Softplus(beta=1, threshold=20)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model_q = NN_q(3, 1, layers)\n",
    "new_model_q.load_state_dict(torch.load(f'{base_path}_Model_q.pt', map_location=DEVICE))\n",
    "new_model_q = new_model_q.to(dtype = torch.float64).to(DEVICE)\n",
    "new_model_q.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "df19abfe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_data = 16\n",
    "\n",
    "y_t_grid_log = torch.linspace(y_lbnd, y_ubnd, n_data)\n",
    "y_t_grid = torch.exp(y_t_grid_log).to(dtype = torch.float64).to(DEVICE)\n",
    "\n",
    "bstar_grid = torch.linspace(b_star_lbnd, b_star_ubnd, n_data).to(dtype = torch.float64).to(DEVICE)\n",
    "\n",
    "btilde_grid = torch.linspace(b_tilde_lbnd, b_tilde_ubnd, n_data).to(dtype = torch.float64).to(DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8e64f8f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def single_step(X, eps, nn_pi, nn_foreign, nn_local, nn_val, nn_qtilde, nn_q):\n",
    "    \n",
    "    n_data = X.shape[0]\n",
    "    \n",
    "    yt = X[0:1]\n",
    "    bstar = X[1:2]\n",
    "    btilde = X[2:3]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pi = nn_pi(X)\n",
    "        bstar_prime = nn_foreign(X)\n",
    "        btilde_prime = nn_local(X)\n",
    "        val = nn_val(X)\n",
    "    \n",
    "    yt_prime = torch.exp(rho_y * torch.log(yt) + eps * eta)\n",
    "    \n",
    "    q_input = torch.cat((yt, bstar_prime, btilde_prime))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        qtilde = nn_qtilde(q_input)\n",
    "        q = nn_q(q_input)\n",
    "    \n",
    "    ct_discriminant = ((btilde / pi) ** 2.0) - 4.0 * (bstar - qstar * (bstar_prime - delta * bstar) - qtilde * (btilde_prime - delta * (btilde / pi)) - yt)\n",
    "    ct_discriminant_clamped = torch.clamp(ct_discriminant, min = 10e-12)\n",
    "    numerator = (-btilde / pi) + (ct_discriminant_clamped ** 0.5)\n",
    "    ct = 0.25 * (numerator ** 2.0)\n",
    "    \n",
    "    zeta = (1.0 / pi) * (ct ** (1.0 - alpha))\n",
    "    \n",
    "    X_prime = torch.cat((yt_prime, bstar_prime, btilde_prime))\n",
    "                         \n",
    "    return X_prime, pi, ct, qtilde, q, bstar_prime, btilde_prime\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "85a2e3ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sim_data(num_periods):\n",
    "\n",
    "    X_sim = torch.empty((num_periods, 3)).to(dtype = torch.float64).to(DEVICE)\n",
    "    pi_sim = torch.empty((num_periods, 1)).to(dtype = torch.float64).to(DEVICE)\n",
    "    ct_sim = torch.empty((num_periods, 1)).to(dtype = torch.float64).to(DEVICE)\n",
    "    qtilde_sim = torch.empty((num_periods, 1)).to(dtype = torch.float64).to(DEVICE)\n",
    "    q_sim = torch.empty((num_periods, 1)).to(dtype = torch.float64).to(DEVICE)  \n",
    "    bstar_sim = torch.empty((num_periods, 1)).to(dtype = torch.float64).to(DEVICE) \n",
    "    btilde_sim = torch.empty((num_periods, 1)).to(dtype = torch.float64).to(DEVICE) \n",
    "    eps = torch.randn(num_periods, dtype = torch.float64).to(DEVICE)\n",
    "\n",
    "    X_sim[0,0] = torch.mean(y_t_grid)\n",
    "    X_sim[0,1] = torch.mean(bstar_grid)\n",
    "    X_sim[0,2] = torch.mean(btilde_grid)\n",
    "\n",
    "    X_old = X_sim[0, :]\n",
    "\n",
    "    for i in range(0, num_periods-1):\n",
    "\n",
    "        eps_use = eps[i]\n",
    "\n",
    "        X_new, pi, ct, qtilde, q, bstar_prime, btilde_prime = single_step(X_old, eps_use, new_model_pi, new_model_foreign, new_model_local, new_model_val, new_model_qtilde, new_model_q)\n",
    "\n",
    "        X_sim[i, :] = X_new\n",
    "\n",
    "        pi_sim[i] = pi\n",
    "        ct_sim[i] = ct\n",
    "        qtilde_sim[i] = qtilde\n",
    "        q_sim[i] = q\n",
    "        bstar_sim[i] = bstar_prime\n",
    "        btilde_sim[i] = btilde_prime\n",
    "        \n",
    "        X_old = X_new\n",
    "\n",
    "        if i%5000 == 0:\n",
    "                print(f'Simulated {i} periods of data')\n",
    "    \n",
    "    sim_data = torch.cat((X_sim, pi_sim, ct_sim, qtilde_sim, q_sim, bstar_sim, btilde_sim), dim = 1)\n",
    "    \n",
    "    return sim_data\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "710f7dfb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulated 0 periods of data\n",
      "Simulated 5000 periods of data\n",
      "Simulated 10000 periods of data\n",
      "Simulated 15000 periods of data\n",
      "Simulated 20000 periods of data\n",
      "Simulated 25000 periods of data\n",
      "Simulated 30000 periods of data\n",
      "Simulated 35000 periods of data\n",
      "Simulated 40000 periods of data\n",
      "Simulated 45000 periods of data\n"
     ]
    }
   ],
   "source": [
    "sim_full = sim_data(50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e2769034",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50000, 9])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "771541eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "drop = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f569ee9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "yt_sim = sim_full[drop:-1, 0].cpu().detach().numpy()\n",
    "dstar_sim = sim_full[drop:-1, 1].cpu().detach().numpy()\n",
    "dtilde_sim = sim_full[drop:-1, 2].cpu().detach().numpy()\n",
    "pi_sim = sim_full[drop:-1, 3].cpu().detach().numpy()\n",
    "ct_sim = sim_full[drop:-1, 4].cpu().detach().numpy()\n",
    "qtilde_sim = sim_full[drop:-1, 5].cpu().detach().numpy()\n",
    "q_sim = sim_full[drop:-1, 6].cpu().detach().numpy()\n",
    "dstar_prime_sim = sim_full[drop:-1, 7].cpu().detach().numpy()\n",
    "dtilde_prime_sim = sim_full[drop:-1, 8].cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "197ce37b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Construct btilde_sim and bstar_sim\n",
    "zeta_sim = (1.0 / pi_sim) * (ct_sim ** (1.0 - alpha))\n",
    "bstar_sim = dstar_sim\n",
    "btilde_sim = dtilde_sim * zeta_sim\n",
    "\n",
    "bt_sim = bstar_sim + btilde_sim\n",
    "\n",
    "pn_sim = ((1 - alpha) / alpha) * ct_sim\n",
    "\n",
    "#Nominal GDP in dollars\n",
    "gdpt_sim = yt_sim + pn_sim\n",
    "\n",
    "gdpr_sim = (alpha ** alpha) * ((1.0 - alpha) ** (1.0 - alpha)) * (yt_sim * (pn_sim ** (alpha - 1.0)) + (pn_sim ** alpha))\n",
    "\n",
    "LC_dif_sim = (btilde_sim - bstar_sim) / gdpt_sim\n",
    "\n",
    "LC_rat_sim = btilde_sim / bt_sim\n",
    "\n",
    "debt_gdpt_sim = bt_sim / gdpt_sim\n",
    "\n",
    "debtLC_gdpt_sim = btilde_sim / gdpt_sim\n",
    "\n",
    "exchange_rate_sim = alpha * pi_sim * (ct_sim ** (alpha - 1.0))\n",
    "\n",
    "trade_balance_sim = (yt_sim - ct_sim) / gdpt_sim\n",
    "\n",
    "LC_yield_sim = np.log(delta + (1.0 / q_sim))\n",
    "LC_spread_sim = LC_yield_sim - r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "acebf755",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set smoothing parameter to annual frequency. Model period corresponds to one year\n",
    "lambda_hp = 6.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c0c66c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "#  HP-filtered series\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "def hp_filtered(series, lam):\n",
    "    cycle, trend = hpfilter(series, lamb = lam)\n",
    "    \n",
    "    return cycle\n",
    "\n",
    "hp_externaldebt_gdp_sim = hp_filtered(debt_gdpt_sim, lambda_hp)\n",
    "\n",
    "hp_share_LC_rat_sim = hp_filtered(LC_rat_sim, lambda_hp)\n",
    "\n",
    "hp_share_LC_dif_sim = hp_filtered(LC_dif_sim, lambda_hp)\n",
    "\n",
    "hp_pi_sim = hp_filtered(pi_sim, lambda_hp)\n",
    "\n",
    "hp_pn_sim = hp_filtered(pn_sim, lambda_hp)\n",
    "\n",
    "hp_exchange_sim = np.log(exchange_rate_sim)\n",
    "hp_exchange_sim = hp_filtered(hp_exchange_sim, lambda_hp)\n",
    "\n",
    "hp_yt_sim = np.log(yt_sim)\n",
    "hp_yt_sim = hp_filtered(hp_yt_sim, lambda_hp)\n",
    "\n",
    "hp_gdpr_sim = np.log(gdpr_sim)\n",
    "hp_gdpr_sim = hp_filtered(hp_gdpr_sim, lambda_hp)\n",
    "\n",
    "hp_gdpt_sim = np.log(gdpt_sim)\n",
    "hp_gdpt_sim = hp_filtered(hp_gdpt_sim, lambda_hp)\n",
    "\n",
    "hp_trade_bal_sim = hp_filtered(trade_balance_sim, lambda_hp)\n",
    "\n",
    "hp_LC_yield_sim = hp_filtered(LC_yield_sim, lambda_hp)\n",
    "hp_LC_spread_sim = hp_filtered(LC_spread_sim, lambda_hp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "534829ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "#  Compute first moments\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "av_externaldebt_gdp = np.mean(debt_gdpt_sim)\n",
    "\n",
    "av_share_LC = np.mean(debtLC_gdpt_sim) / np.mean(debt_gdpt_sim)\n",
    "\n",
    "av_pi = np.mean(pi_sim)\n",
    "\n",
    "av_xr_sim = np.mean(exchange_rate_sim)\n",
    "\n",
    "av_dstar_sim = np.mean(dstar_sim)\n",
    "\n",
    "av_dtilde_sim = np.mean(dtilde_sim)\n",
    "\n",
    "av_zeta_sim = np.mean(zeta_sim)\n",
    "\n",
    "av_LC_yield_sim = np.mean(LC_yield_sim)\n",
    "\n",
    "av_LC_spread_sim = np.mean(LC_spread_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "eb48f1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "#  Compute standard deviations\n",
    "# -----------------------------------------------------------------------------\n",
    "sd_externaldebt_gdp = np.std(debt_gdpt_sim)\n",
    "\n",
    "sd_share_LC_rat = np.std(LC_rat_sim)\n",
    "\n",
    "sd_share_LC_dif = np.std(LC_dif_sim)\n",
    "\n",
    "sd_pi = np.std(pi_sim)\n",
    "\n",
    "sd_pn = np.std(pn_sim)\n",
    "\n",
    "sd_exchange_rate = np.std(np.log(exchange_rate_sim))\n",
    "\n",
    "sd_yt = np.std(yt_sim)\n",
    "\n",
    "sd_gdpr = np.std(gdpr_sim)\n",
    "\n",
    "sd_gdpt = np.std(gdpt_sim)\n",
    "\n",
    "sd_LC_yield = np.std(LC_yield_sim)\n",
    "\n",
    "sd_LC_spread = np.std(LC_spread_sim)\n",
    "\n",
    "sd_externaldebt_gdp_hp = np.std(hp_externaldebt_gdp_sim)\n",
    "\n",
    "sd_share_LC_rat_hp = np.std(hp_share_LC_rat_sim)\n",
    "\n",
    "sd_share_LC_dif_hp = np.std(hp_share_LC_dif_sim)\n",
    "\n",
    "sd_pi_hp = np.std(hp_pi_sim)\n",
    "\n",
    "sd_pn_hp = np.std(hp_pn_sim)\n",
    "\n",
    "sd_exchange_hp = np.std(hp_exchange_sim)\n",
    "\n",
    "sd_yt_hp = np.std(hp_yt_sim)\n",
    "\n",
    "sd_gdpr_hp = np.std(hp_gdpr_sim)\n",
    "\n",
    "sd_gdpt_hp = np.std(hp_gdpt_sim)\n",
    "\n",
    "sd_tby_hp = np.std(hp_trade_bal_sim)\n",
    "\n",
    "sd_LC_yield_hp = np.std(hp_LC_yield_sim)\n",
    "\n",
    "sd_LC_spread_hp = np.std(hp_LC_spread_sim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "436c18d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "#  Compute correlations\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "def corr(x, y):\n",
    "    return np.corrcoef(x, y)[0,1]\n",
    "\n",
    "corr_hp_gdp_externaldebt_gdp = corr(hp_gdpr_sim, hp_externaldebt_gdp_sim)\n",
    "\n",
    "corr_hp_gdp_share_LC_rat = corr(hp_gdpr_sim, hp_share_LC_rat_sim)\n",
    "\n",
    "corr_hp_gdp_share_LC_dif = corr(hp_gdpr_sim, hp_share_LC_dif_sim)\n",
    "\n",
    "corr_hp_gdp_pi = corr(hp_gdpr_sim, hp_pi_sim)\n",
    "\n",
    "corr_hp_gdp_exchange = corr(hp_gdpr_sim, hp_exchange_sim)\n",
    "\n",
    "corr_hp_gdp_tby = corr(hp_gdpr_sim, hp_trade_bal_sim)\n",
    "\n",
    "corr_hp_gdp_LC_yield = corr(hp_gdpr_sim, hp_LC_yield_sim)\n",
    "\n",
    "corr_hp_gdp_LC_spread = corr(hp_gdpr_sim, hp_LC_spread_sim)\n",
    "\n",
    "# Correlations with yt\n",
    "corr_hp_yt_externaldebt_gdp = corr(hp_yt_sim, hp_externaldebt_gdp_sim)\n",
    "\n",
    "corr_hp_yt_share_LC_rat = corr(hp_yt_sim, hp_share_LC_rat_sim)\n",
    "\n",
    "corr_hp_yt_share_LC_dif = corr(hp_yt_sim, hp_share_LC_dif_sim)\n",
    "\n",
    "corr_hp_yt_pi = corr(hp_yt_sim, hp_pi_sim)\n",
    "\n",
    "corr_hp_yt_pn = corr(hp_yt_sim, hp_pn_sim)\n",
    "\n",
    "corr_hp_yt_exchange = corr(hp_yt_sim, hp_exchange_sim)\n",
    "\n",
    "corr_hp_yt_tby = corr(hp_yt_sim, hp_trade_bal_sim)\n",
    "\n",
    "corr_hp_yt_LC_yield = corr(hp_yt_sim, hp_LC_yield_sim)\n",
    "\n",
    "corr_hp_yt_LC_spread = corr(hp_yt_sim, hp_LC_spread_sim)\n",
    "\n",
    "# Correlations with gdpt\n",
    "corr_hp_gdpt_externaldebt_gdp = corr(hp_gdpt_sim, hp_externaldebt_gdp_sim)\n",
    "\n",
    "corr_hp_gdpt_share_LC_rat = corr(hp_gdpt_sim, hp_share_LC_rat_sim)\n",
    "\n",
    "corr_hp_gdpt_share_LC_dif = corr(hp_gdpt_sim, hp_share_LC_dif_sim)\n",
    "\n",
    "corr_hp_gdpt_pi = corr(hp_gdpt_sim, hp_pi_sim)\n",
    "\n",
    "corr_hp_gdpt_exchange = corr(hp_gdpt_sim, hp_exchange_sim)\n",
    "\n",
    "corr_hp_gdpt_tby = corr(hp_gdpt_sim, hp_trade_bal_sim)\n",
    "\n",
    "corr_hp_gdpt_LC_yield = corr(hp_gdpt_sim, hp_LC_yield_sim)\n",
    "\n",
    "corr_hp_gdpt_LC_spread = corr(hp_gdpt_sim, hp_LC_spread_sim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "502c558f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "#  Store moments in dictionary\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "moments = {\n",
    "    # Averages\n",
    "    'av_externaldebt_gdp': av_externaldebt_gdp,\n",
    "    'av_share_LC': av_share_LC,\n",
    "    'av_pi': av_pi,\n",
    "    'av_LC_yield_sim': av_LC_yield_sim,\n",
    "    'av_LC_spread_sim':av_LC_spread_sim,\n",
    "    \n",
    "    # Standard deviations (levels)\n",
    "    'sd_externaldebt_gdp': sd_externaldebt_gdp,\n",
    "    'sd_share_LC_rat': sd_share_LC_rat,\n",
    "    'sd_share_LC_dif': sd_share_LC_dif,\n",
    "    'sd_pi': sd_pi,\n",
    "    'sd_exchange_rate': sd_exchange_rate,\n",
    "    'sd_yt': sd_yt,\n",
    "    'sd_gdpr': sd_gdpr,\n",
    "    'sd_gdpt': sd_gdpt,\n",
    "    'sd_LC_yield': sd_LC_yield,\n",
    "    'sd_LC_spread' : sd_LC_spread,\n",
    "    \n",
    "    # Standard deviations (HP-filtered series)\n",
    "    'sd_externaldebt_gdp_hp': sd_externaldebt_gdp_hp,\n",
    "    'sd_share_LC_rat_hp': sd_share_LC_rat_hp,\n",
    "    'sd_share_LC_dif_hp': sd_share_LC_dif_hp,\n",
    "    'sd_pi_hp': sd_pi_hp,\n",
    "    'sd_exchange_hp': sd_exchange_hp,\n",
    "    'sd_yt_hp': sd_yt_hp,\n",
    "    'sd_gdpr_hp': sd_gdpr_hp,\n",
    "    'sd_gdpt_hp' : sd_gdpt_hp,\n",
    "    'sd_tby_hp': sd_tby_hp,\n",
    "    'sd_LC_yield_hp':sd_LC_yield_hp,\n",
    "    'sd_LC_spread_hp': sd_LC_spread_hp,\n",
    "    \n",
    "    # Correlations between HP-filtered GDP and other variables\n",
    "    'corr_hp_gdp_externaldebt_gdp': corr_hp_gdp_externaldebt_gdp,\n",
    "    'corr_hp_gdp_share_LC_rat': corr_hp_gdp_share_LC_rat,\n",
    "    'corr_hp_gdp_share_LC_dif': corr_hp_gdp_share_LC_dif,\n",
    "    'corr_hp_gdp_pi': corr_hp_gdp_pi,\n",
    "    'corr_hp_gdp_exchange': corr_hp_gdp_exchange,\n",
    "    'corr_hp_gdp_tby': corr_hp_gdp_tby,\n",
    "    'corr_hp_gdp_LC_yield': corr_hp_gdp_LC_yield,\n",
    "    'corr_hp_gdp_LC_spread': corr_hp_gdp_LC_spread,\n",
    "    \n",
    "    # Correlations between HP-filtered yt and other variables\n",
    "    'corr_hp_yt_externaldebt_gdp': corr_hp_yt_externaldebt_gdp,\n",
    "    'corr_hp_yt_share_LC_rat': corr_hp_yt_share_LC_rat,\n",
    "    'corr_hp_yt_share_LC_dif': corr_hp_yt_share_LC_dif,\n",
    "    'corr_hp_yt_pi': corr_hp_yt_pi,\n",
    "    'corr_hp_yt_exchange': corr_hp_yt_exchange,\n",
    "    'corr_hp_yt_tby': corr_hp_yt_tby,\n",
    "    'corr_hp_yt_LC_yield' : corr_hp_yt_LC_yield,\n",
    "    'corr_hp_yt_LC_spread': corr_hp_yt_LC_spread\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "13a82587",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'av_externaldebt_gdp': 0.03371833776683496,\n",
       " 'av_share_LC': -0.6121440400197636,\n",
       " 'av_pi': 1.0520455316624227,\n",
       " 'av_xr_sim': 0.5363314677674444,\n",
       " 'av_dstar_sim': 0.10662147467615092,\n",
       " 'av_dtilde_sim': -0.043425937056155856,\n",
       " 'av_zeta_sim': 0.9331864994386172,\n",
       " 'av_LC_yield_sim': 0.7510227243771228,\n",
       " 'av_LC_spread_sim': 0.7120227243771228,\n",
       " 'sd_externaldebt_gdp': 0.0018453282366034255,\n",
       " 'sd_share_LC_rat': 0.026162065380063146,\n",
       " 'sd_share_LC_dif': 0.002502802961343695,\n",
       " 'sd_pi': 5.492797744359008e-05,\n",
       " 'sd_pn': 0.061077967157454616,\n",
       " 'sd_exchange_rate': 0.03152902077385794,\n",
       " 'sd_yt': 0.059251506423559905,\n",
       " 'sd_gdpr': 0.029675673947454836,\n",
       " 'sd_gdpt': 0.11442825496500131,\n",
       " 'sd_LC_yield': 0.00011231206078204429,\n",
       " 'sd_LC_spread': 0.00011231206078204429,\n",
       " 'sd_externaldebt_gdp_hp': 0.0006051084721633818,\n",
       " 'sd_share_LC_rat_hp': 0.01151251347737062,\n",
       " 'sd_share_LC_dif_hp': 0.000932022249170027,\n",
       " 'sd_pi_hp': 2.0409924346244485e-05,\n",
       " 'sd_pn_hp': 0.02574962335996252,\n",
       " 'sd_exchange_hp': 0.013238881596962031,\n",
       " 'sd_yt_hp': 0.023303865405846693,\n",
       " 'sd_gdpr_hp': 0.011849982955600016,\n",
       " 'sd_gdpt_hp': 0.018331847164640907,\n",
       " 'sd_tby_hp': 0.016893158245613975,\n",
       " 'sd_LC_yield_hp': 5.161668567018102e-05,\n",
       " 'sd_LC_spread_hp': 5.161668567018199e-05,\n",
       " 'corr_hp_gdp_externaldebt_gdp': -0.7145793966212052,\n",
       " 'corr_hp_gdp_share_LC_rat': -0.06637020787427222,\n",
       " 'corr_hp_gdp_share_LC_dif': 0.9752920854284998,\n",
       " 'corr_hp_gdp_pi': 0.019313495757263734,\n",
       " 'corr_hp_gdp_exchange': -0.06327752992162432,\n",
       " 'corr_hp_gdp_tby': 0.6394218274305942,\n",
       " 'corr_hp_gdp_LC_yield': 0.025218435773222418,\n",
       " 'corr_hp_gdp_LC_spread': 0.025218435773236292,\n",
       " 'corr_hp_yt_externaldebt_gdp': -0.7280410248279007,\n",
       " 'corr_hp_yt_share_LC_rat': -0.08569148205824613,\n",
       " 'corr_hp_yt_share_LC_dif': 0.9783671773593524,\n",
       " 'corr_hp_yt_pi': 0.03944355195007889,\n",
       " 'corr_hp_yt_pn': 0.08326686405816827,\n",
       " 'corr_hp_yt_exchange': -0.08345103472940296,\n",
       " 'corr_hp_yt_tby': 0.6238595167532459,\n",
       " 'corr_hp_yt_LC_yield': 0.03775863088656939,\n",
       " 'corr_hp_yt_LC_spread': 0.03775863088658316}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "416887fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2074"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base = Path(path or \".\").expanduser().resolve()\n",
    "outfile = base / \"moments.json\"\n",
    "outfile.write_text(json.dumps(moments, indent=2, sort_keys=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb88413",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "enviro_dis",
   "language": "python",
   "name": "enviro_dis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
