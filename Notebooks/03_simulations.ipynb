{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd0e5c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Script for simulating data from model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf269c11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7ed8d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import json\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.filters.hp_filter import hpfilter\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.init import kaiming_uniform_\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510ab14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(os.getenv('OP_DEVICE', 'cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "DTYPE  = torch.float64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c490490",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "weight = 0.7\n",
    "neg_weight = 10.0\n",
    "batch_size = 128\n",
    "\n",
    "layers = [50, 50, 50]\n",
    "seed = 33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75980bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(seed)            \n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)    \n",
    "    torch.cuda.manual_seed_all(seed)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebcc6a4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "#  Hardâ€‘wired model parameters\n",
    "# -----------------------------------------------------------------------------\n",
    "crra = 5.0\n",
    "beta = 0.9\n",
    "alpha = 0.5\n",
    "\n",
    "psi = 7.08\n",
    "pi_star = 1.0484\n",
    "\n",
    "rho_y = 0.8118\n",
    "eta = 0.0347\n",
    "sigma_y = eta/np.sqrt(1.0 - (rho_y ** 2.0))\n",
    "\n",
    "mu = 0.0\n",
    "y_ubnd = mu + 3.0 * sigma_y\n",
    "y_lbnd = mu - 3.0 * sigma_y\n",
    "\n",
    "b_star_ubnd = 0.3\n",
    "b_star_lbnd = -0.1\n",
    "\n",
    "b_tilde_ubnd = 0.3\n",
    "b_tilde_lbnd = -0.1\n",
    "\n",
    "kappa = 40.0\n",
    "\n",
    "r = 0.039\n",
    "R = np.exp(r)\n",
    "delta = 0.757\n",
    "\n",
    "qstar = 1.0 / (R - delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11acae00",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = ''\n",
    "base_path = f'{path}/pickle/kappa{kappa}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbd32ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_int = 19\n",
    "\n",
    "x_int_norm, w_int = np.polynomial.hermite.hermgauss(n_int)\n",
    "w_int = w_int/np.sqrt(np.pi)\n",
    "x_int_norm = x_int_norm * np.sqrt(2)\n",
    "\n",
    "w_int = torch.from_numpy(w_int).to(DEVICE)\n",
    "x_int_norm = torch.from_numpy(x_int_norm).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fda5a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class NN_pi(nn.Module):\n",
    "    def __init__(self, in_szs, out_szs, layers):\n",
    "        super().__init__()\n",
    "\n",
    "        layerlist = []\n",
    "        n_in = in_szs\n",
    "        \n",
    "        for i in layers:\n",
    "            kaiming_uniform_(nn.Linear(n_in, i).weight, nonlinearity='leaky_relu')\n",
    "            layerlist.append(nn.Linear(n_in, i))\n",
    "            layerlist.append(nn.LeakyReLU())\n",
    "            n_in = i\n",
    "        \n",
    "        layerlist.append(nn.Linear(layers[-1], out_szs))\n",
    "        layerlist.append(nn.Sigmoid())\n",
    "        \n",
    "        self.layers = nn.Sequential(*layerlist)\n",
    "                \n",
    "    def forward(self, x):\n",
    "        \n",
    "        pred = self.layers(x)\n",
    "        \n",
    "        pred = pred * (1.1 - 1.0) + 1.0\n",
    "                    \n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4152a94e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class NN_foreign(nn.Module):\n",
    "    def __init__(self, in_szs, out_szs, layers):\n",
    "        super().__init__()\n",
    "\n",
    "        layerlist = []\n",
    "        n_in = in_szs\n",
    "        \n",
    "        for i in layers:\n",
    "            kaiming_uniform_(nn.Linear(n_in, i).weight, nonlinearity='leaky_relu')\n",
    "            layerlist.append(nn.Linear(n_in, i))\n",
    "            layerlist.append(nn.LeakyReLU())\n",
    "            n_in = i\n",
    "        \n",
    "        layerlist.append(nn.Linear(layers[-1], out_szs))\n",
    "        layerlist.append(nn.Identity())\n",
    "        \n",
    "        self.layers = nn.Sequential(*layerlist)\n",
    "                \n",
    "    def forward(self, x):\n",
    "        \n",
    "        pred = self.layers(x)\n",
    "                    \n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e633850",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class NN_local(nn.Module):\n",
    "    def __init__(self, in_szs, out_szs, layers):\n",
    "        super().__init__()\n",
    "\n",
    "        layerlist = []\n",
    "        n_in = in_szs\n",
    "        \n",
    "        for i in layers:\n",
    "            kaiming_uniform_(nn.Linear(n_in, i).weight, nonlinearity='leaky_relu')\n",
    "            layerlist.append(nn.Linear(n_in, i))\n",
    "            layerlist.append(nn.LeakyReLU())\n",
    "            n_in = i\n",
    "        \n",
    "        layerlist.append(nn.Linear(layers[-1], out_szs))\n",
    "        layerlist.append(nn.Identity())\n",
    "        \n",
    "        self.layers = nn.Sequential(*layerlist)\n",
    "                \n",
    "    def forward(self, x):\n",
    "        \n",
    "        pred = self.layers(x)\n",
    "                    \n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39af040d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class NN_val(nn.Module):\n",
    "    def __init__(self, in_szs, out_szs, layers):\n",
    "        super().__init__()\n",
    "\n",
    "        layerlist = []\n",
    "        n_in = in_szs\n",
    "        \n",
    "        for i in layers:\n",
    "            kaiming_uniform_(nn.Linear(n_in, i).weight, nonlinearity='leaky_relu')\n",
    "            layerlist.append(nn.Linear(n_in, i))\n",
    "            layerlist.append(nn.LeakyReLU())\n",
    "            n_in = i\n",
    "        \n",
    "        layerlist.append(nn.Linear(layers[-1], out_szs))\n",
    "        layerlist.append(nn.Identity())\n",
    "        \n",
    "        self.layers = nn.Sequential(*layerlist)\n",
    "                \n",
    "    def forward(self, x):\n",
    "        \n",
    "        pred = self.layers(x)\n",
    "                    \n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b315c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class NN_qtilde(nn.Module):\n",
    "    def __init__(self, in_szs, out_szs, layers):\n",
    "        super().__init__()\n",
    "\n",
    "        layerlist = []\n",
    "        n_in = in_szs\n",
    "        \n",
    "        for i in layers:\n",
    "            kaiming_uniform_(nn.Linear(n_in, i).weight, nonlinearity='leaky_relu')\n",
    "            layerlist.append(nn.Linear(n_in, i))\n",
    "            layerlist.append(nn.LeakyReLU())\n",
    "            n_in = i\n",
    "        \n",
    "        layerlist.append(nn.Linear(layers[-1], out_szs))\n",
    "        layerlist.append(nn.Sigmoid())\n",
    "        \n",
    "        self.layers = nn.Sequential(*layerlist)\n",
    "                \n",
    "    def forward(self, x):\n",
    "        \n",
    "        pred = self.layers(x)\n",
    "        \n",
    "        pred = pred * 10.0\n",
    "                    \n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6680ea86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class NN_q(nn.Module):\n",
    "    def __init__(self, in_szs, out_szs, layers):\n",
    "        super().__init__()\n",
    "\n",
    "        layerlist = []\n",
    "        n_in = in_szs\n",
    "        \n",
    "        for i in layers:\n",
    "            kaiming_uniform_(nn.Linear(n_in, i).weight, nonlinearity='leaky_relu')\n",
    "            layerlist.append(nn.Linear(n_in, i))\n",
    "            layerlist.append(nn.LeakyReLU())\n",
    "            n_in = i\n",
    "        \n",
    "        layerlist.append(nn.Linear(layers[-1], out_szs))\n",
    "        layerlist.append(nn.Softplus())\n",
    "        \n",
    "        self.layers = nn.Sequential(*layerlist)\n",
    "                \n",
    "    def forward(self, x):\n",
    "        \n",
    "        pred = self.layers(x)\n",
    "                                    \n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b300c217",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_model_pi = NN_pi(3, 1, layers)\n",
    "new_model_pi.load_state_dict(torch.load(f'{base_path}_Model_pi.pt', map_location=DEVICE))\n",
    "new_model_pi = new_model_pi.to(dtype = torch.float64).to(DEVICE)\n",
    "new_model_pi.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c666c41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_model_foreign = NN_foreign(3, 1, layers)\n",
    "new_model_foreign.load_state_dict(torch.load(f'{base_path}_Model_foreign.pt', map_location=DEVICE))\n",
    "new_model_foreign = new_model_foreign.to(dtype = torch.float64).to(DEVICE)\n",
    "new_model_foreign.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea20e7d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_model_local = NN_local(3, 1, layers)\n",
    "new_model_local.load_state_dict(torch.load(f'{base_path}_Model_local.pt', map_location=DEVICE))\n",
    "new_model_local = new_model_local.to(dtype = torch.float64).to(DEVICE)\n",
    "new_model_local.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b78ffe8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_model_val = NN_val(3, 1, layers)\n",
    "new_model_val.load_state_dict(torch.load(f'{base_path}_Model_val.pt', map_location=DEVICE))\n",
    "new_model_val = new_model_val.to(dtype = torch.float64).to(DEVICE)\n",
    "new_model_val.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137c87a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_model_qtilde = NN_qtilde(3, 1, layers)\n",
    "new_model_qtilde.load_state_dict(torch.load(f'{base_path}_Model_qtilde.pt', map_location=DEVICE))\n",
    "new_model_qtilde = new_model_qtilde.to(dtype = torch.float64).to(DEVICE)\n",
    "new_model_qtilde.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b670af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_model_q = NN_q(3, 1, layers)\n",
    "new_model_q.load_state_dict(torch.load(f'{base_path}_Model_q.pt', map_location=DEVICE))\n",
    "new_model_q = new_model_q.to(dtype = torch.float64).to(DEVICE)\n",
    "new_model_q.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251f99f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_data = 16\n",
    "\n",
    "y_t_grid_log = torch.linspace(y_lbnd, y_ubnd, n_data)\n",
    "y_t_grid = torch.exp(y_t_grid_log).to(dtype = torch.float64).to(DEVICE)\n",
    "\n",
    "bstar_grid = torch.linspace(b_star_lbnd, b_star_ubnd, n_data).to(dtype = torch.float64).to(DEVICE)\n",
    "\n",
    "btilde_grid = torch.linspace(b_tilde_lbnd, b_tilde_ubnd, n_data).to(dtype = torch.float64).to(DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b1825b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def single_step(X, eps, nn_pi, nn_foreign, nn_local, nn_val, nn_qtilde, nn_q):\n",
    "    \n",
    "    n_data = X.shape[0]\n",
    "    \n",
    "    yt = X[0:1]\n",
    "    bstar = X[1:2]\n",
    "    btilde = X[2:3]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pi = nn_pi(X)\n",
    "        bstar_prime = nn_foreign(X)\n",
    "        btilde_prime = nn_local(X)\n",
    "        val = nn_val(X)\n",
    "    \n",
    "    yt_prime = torch.exp(rho_y * torch.log(yt) + eps * eta)\n",
    "    \n",
    "    q_input = torch.cat((yt, bstar_prime, btilde_prime))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        qtilde = nn_qtilde(q_input)\n",
    "        q = nn_q(q_input)\n",
    "    \n",
    "    ct_discriminant = ((btilde / pi) ** 2.0) - 4.0 * (bstar - qstar * (bstar_prime - delta * bstar) - qtilde * (btilde_prime - delta * (btilde / pi)) - yt)\n",
    "    ct_discriminant_clamped = torch.clamp(ct_discriminant, min = 10e-12)\n",
    "    numerator = (-btilde / pi) + (ct_discriminant_clamped ** 0.5)\n",
    "    ct = 0.25 * (numerator ** 2.0)\n",
    "    \n",
    "    zeta = (1.0 / pi) * (ct ** (1.0 - alpha))\n",
    "    \n",
    "    X_prime = torch.cat((yt_prime, bstar_prime, btilde_prime))\n",
    "                         \n",
    "    return X_prime, pi, ct, qtilde, q, bstar_prime, btilde_prime\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c3b7b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sim_data(num_periods):\n",
    "\n",
    "    X_sim = torch.empty((num_periods, 3)).to(dtype = torch.float64).to(DEVICE)\n",
    "    pi_sim = torch.empty((num_periods, 1)).to(dtype = torch.float64).to(DEVICE)\n",
    "    ct_sim = torch.empty((num_periods, 1)).to(dtype = torch.float64).to(DEVICE)\n",
    "    qtilde_sim = torch.empty((num_periods, 1)).to(dtype = torch.float64).to(DEVICE)\n",
    "    q_sim = torch.empty((num_periods, 1)).to(dtype = torch.float64).to(DEVICE)  \n",
    "    bstar_sim = torch.empty((num_periods, 1)).to(dtype = torch.float64).to(DEVICE) \n",
    "    btilde_sim = torch.empty((num_periods, 1)).to(dtype = torch.float64).to(DEVICE) \n",
    "    eps = torch.randn(num_periods, dtype = torch.float64).to(DEVICE)\n",
    "\n",
    "    X_sim[0,0] = torch.mean(y_t_grid)\n",
    "    X_sim[0,1] = torch.mean(bstar_grid)\n",
    "    X_sim[0,2] = torch.mean(btilde_grid)\n",
    "\n",
    "    X_old = X_sim[0, :]\n",
    "\n",
    "    for i in range(0, num_periods-1):\n",
    "\n",
    "        eps_use = eps[i]\n",
    "\n",
    "        X_new, pi, ct, qtilde, q, bstar_prime, btilde_prime = single_step(X_old, eps_use, new_model_pi, new_model_foreign, new_model_local, new_model_val, new_model_qtilde, new_model_q)\n",
    "\n",
    "        X_sim[i, :] = X_new\n",
    "\n",
    "        pi_sim[i] = pi\n",
    "        ct_sim[i] = ct\n",
    "        qtilde_sim[i] = qtilde\n",
    "        q_sim[i] = q\n",
    "        bstar_sim[i] = bstar_prime\n",
    "        btilde_sim[i] = btilde_prime\n",
    "        \n",
    "        X_old = X_new\n",
    "\n",
    "        if i%5000 == 0:\n",
    "                print(f'Simulated {i} periods of data')\n",
    "    \n",
    "    sim_data = torch.cat((X_sim, pi_sim, ct_sim, qtilde_sim, q_sim, bstar_sim, btilde_sim), dim = 1)\n",
    "    \n",
    "    return sim_data\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ea6360",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sim_full = sim_data(50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c81b333",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sim_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14db9a96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "drop = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28c66c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "yt_sim = sim_full[drop:-1, 0].cpu().detach().numpy()\n",
    "dstar_sim = sim_full[drop:-1, 1].cpu().detach().numpy()\n",
    "dtilde_sim = sim_full[drop:-1, 2].cpu().detach().numpy()\n",
    "pi_sim = sim_full[drop:-1, 3].cpu().detach().numpy()\n",
    "ct_sim = sim_full[drop:-1, 4].cpu().detach().numpy()\n",
    "qtilde_sim = sim_full[drop:-1, 5].cpu().detach().numpy()\n",
    "q_sim = sim_full[drop:-1, 6].cpu().detach().numpy()\n",
    "dstar_prime_sim = sim_full[drop:-1, 7].cpu().detach().numpy()\n",
    "dtilde_prime_sim = sim_full[drop:-1, 8].cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbd21eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Construct btilde_sim and bstar_sim\n",
    "zeta_sim = (1.0 / pi_sim) * (ct_sim ** (1.0 - alpha))\n",
    "bstar_sim = dstar_sim\n",
    "btilde_sim = dtilde_sim * zeta_sim\n",
    "\n",
    "bt_sim = bstar_sim + btilde_sim\n",
    "\n",
    "pn_sim = ((1 - alpha) / alpha) * ct_sim\n",
    "\n",
    "#Nominal GDP in dollars\n",
    "gdpt_sim = yt_sim + pn_sim\n",
    "\n",
    "gdpr_sim = (alpha ** alpha) * ((1.0 - alpha) ** (1.0 - alpha)) * (yt_sim * (pn_sim ** (alpha - 1.0)) + (pn_sim ** alpha))\n",
    "\n",
    "LC_dif_sim = (btilde_sim - bstar_sim) / gdpt_sim\n",
    "\n",
    "LC_rat_sim = btilde_sim / bt_sim\n",
    "\n",
    "debt_gdpt_sim = bt_sim / gdpt_sim\n",
    "\n",
    "debtLC_gdpt_sim = btilde_sim / gdpt_sim\n",
    "\n",
    "exchange_rate_sim = alpha * pi_sim * (ct_sim ** (alpha - 1.0))\n",
    "\n",
    "trade_balance_sim = (yt_sim - ct_sim) / gdpt_sim\n",
    "\n",
    "LC_yield_sim = np.log(delta + (1.0 / q_sim))\n",
    "LC_spread_sim = LC_yield_sim - r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925cca3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set smoothing parameter to annual frequency. Model period corresponds to one year\n",
    "lambda_hp = 6.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36178970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "#  HP-filtered series\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "def hp_filtered(series, lam):\n",
    "    cycle, trend = hpfilter(series, lamb = lam)\n",
    "    \n",
    "    return cycle\n",
    "\n",
    "hp_externaldebt_gdp_sim = hp_filtered(debt_gdpt_sim, lambda_hp)\n",
    "\n",
    "hp_share_LC_rat_sim = hp_filtered(LC_rat_sim, lambda_hp)\n",
    "\n",
    "hp_share_LC_dif_sim = hp_filtered(LC_dif_sim, lambda_hp)\n",
    "\n",
    "hp_pi_sim = hp_filtered(pi_sim, lambda_hp)\n",
    "\n",
    "hp_pn_sim = hp_filtered(pn_sim, lambda_hp)\n",
    "\n",
    "hp_exchange_sim = np.log(exchange_rate_sim)\n",
    "hp_exchange_sim = hp_filtered(hp_exchange_sim, lambda_hp)\n",
    "\n",
    "hp_yt_sim = np.log(yt_sim)\n",
    "hp_yt_sim = hp_filtered(hp_yt_sim, lambda_hp)\n",
    "\n",
    "hp_gdpr_sim = np.log(gdpr_sim)\n",
    "hp_gdpr_sim = hp_filtered(hp_gdpr_sim, lambda_hp)\n",
    "\n",
    "hp_gdpt_sim = np.log(gdpt_sim)\n",
    "hp_gdpt_sim = hp_filtered(hp_gdpt_sim, lambda_hp)\n",
    "\n",
    "hp_trade_bal_sim = hp_filtered(trade_balance_sim, lambda_hp)\n",
    "\n",
    "hp_LC_yield_sim = hp_filtered(LC_yield_sim, lambda_hp)\n",
    "hp_LC_spread_sim = hp_filtered(LC_spread_sim, lambda_hp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9e41c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "#  Compute first moments\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "av_externaldebt_gdp = np.mean(debt_gdpt_sim)\n",
    "\n",
    "av_share_LC = np.mean(debtLC_gdpt_sim) / np.mean(debt_gdpt_sim)\n",
    "\n",
    "av_pi = np.mean(pi_sim)\n",
    "\n",
    "av_xr_sim = np.mean(exchange_rate_sim)\n",
    "\n",
    "av_dstar_sim = np.mean(dstar_sim)\n",
    "\n",
    "av_dtilde_sim = np.mean(dtilde_sim)\n",
    "\n",
    "av_zeta_sim = np.mean(zeta_sim)\n",
    "\n",
    "av_LC_yield_sim = np.mean(LC_yield_sim)\n",
    "\n",
    "av_LC_spread_sim = np.mean(LC_spread_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028fa5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "#  Compute standard deviations\n",
    "# -----------------------------------------------------------------------------\n",
    "sd_externaldebt_gdp = np.std(debt_gdpt_sim)\n",
    "\n",
    "sd_share_LC_rat = np.std(LC_rat_sim)\n",
    "\n",
    "sd_share_LC_dif = np.std(LC_dif_sim)\n",
    "\n",
    "sd_pi = np.std(pi_sim)\n",
    "\n",
    "sd_pn = np.std(pn_sim)\n",
    "\n",
    "sd_exchange_rate = np.std(np.log(exchange_rate_sim))\n",
    "\n",
    "sd_yt = np.std(yt_sim)\n",
    "\n",
    "sd_gdpr = np.std(gdpr_sim)\n",
    "\n",
    "sd_gdpt = np.std(gdpt_sim)\n",
    "\n",
    "sd_LC_yield = np.std(LC_yield_sim)\n",
    "\n",
    "sd_LC_spread = np.std(LC_spread_sim)\n",
    "\n",
    "sd_externaldebt_gdp_hp = np.std(hp_externaldebt_gdp_sim)\n",
    "\n",
    "sd_share_LC_rat_hp = np.std(hp_share_LC_rat_sim)\n",
    "\n",
    "sd_share_LC_dif_hp = np.std(hp_share_LC_dif_sim)\n",
    "\n",
    "sd_pi_hp = np.std(hp_pi_sim)\n",
    "\n",
    "sd_pn_hp = np.std(hp_pn_sim)\n",
    "\n",
    "sd_exchange_hp = np.std(hp_exchange_sim)\n",
    "\n",
    "sd_yt_hp = np.std(hp_yt_sim)\n",
    "\n",
    "sd_gdpr_hp = np.std(hp_gdpr_sim)\n",
    "\n",
    "sd_gdpt_hp = np.std(hp_gdpt_sim)\n",
    "\n",
    "sd_tby_hp = np.std(hp_trade_bal_sim)\n",
    "\n",
    "sd_LC_yield_hp = np.std(hp_LC_yield_sim)\n",
    "\n",
    "sd_LC_spread_hp = np.std(hp_LC_spread_sim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f359b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "#  Compute correlations\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "def corr(x, y):\n",
    "    return np.corrcoef(x, y)[0,1]\n",
    "\n",
    "corr_hp_gdp_externaldebt_gdp = corr(hp_gdpr_sim, hp_externaldebt_gdp_sim)\n",
    "\n",
    "corr_hp_gdp_share_LC_rat = corr(hp_gdpr_sim, hp_share_LC_rat_sim)\n",
    "\n",
    "corr_hp_gdp_share_LC_dif = corr(hp_gdpr_sim, hp_share_LC_dif_sim)\n",
    "\n",
    "corr_hp_gdp_pi = corr(hp_gdpr_sim, hp_pi_sim)\n",
    "\n",
    "corr_hp_gdp_exchange = corr(hp_gdpr_sim, hp_exchange_sim)\n",
    "\n",
    "corr_hp_gdp_tby = corr(hp_gdpr_sim, hp_trade_bal_sim)\n",
    "\n",
    "corr_hp_gdp_LC_yield = corr(hp_gdpr_sim, hp_LC_yield_sim)\n",
    "\n",
    "corr_hp_gdp_LC_spread = corr(hp_gdpr_sim, hp_LC_spread_sim)\n",
    "\n",
    "# Correlations with yt\n",
    "corr_hp_yt_externaldebt_gdp = corr(hp_yt_sim, hp_externaldebt_gdp_sim)\n",
    "\n",
    "corr_hp_yt_share_LC_rat = corr(hp_yt_sim, hp_share_LC_rat_sim)\n",
    "\n",
    "corr_hp_yt_share_LC_dif = corr(hp_yt_sim, hp_share_LC_dif_sim)\n",
    "\n",
    "corr_hp_yt_pi = corr(hp_yt_sim, hp_pi_sim)\n",
    "\n",
    "corr_hp_yt_pn = corr(hp_yt_sim, hp_pn_sim)\n",
    "\n",
    "corr_hp_yt_exchange = corr(hp_yt_sim, hp_exchange_sim)\n",
    "\n",
    "corr_hp_yt_tby = corr(hp_yt_sim, hp_trade_bal_sim)\n",
    "\n",
    "corr_hp_yt_LC_yield = corr(hp_yt_sim, hp_LC_yield_sim)\n",
    "\n",
    "corr_hp_yt_LC_spread = corr(hp_yt_sim, hp_LC_spread_sim)\n",
    "\n",
    "# Correlations with gdpt\n",
    "corr_hp_gdpt_externaldebt_gdp = corr(hp_gdpt_sim, hp_externaldebt_gdp_sim)\n",
    "\n",
    "corr_hp_gdpt_share_LC_rat = corr(hp_gdpt_sim, hp_share_LC_rat_sim)\n",
    "\n",
    "corr_hp_gdpt_share_LC_dif = corr(hp_gdpt_sim, hp_share_LC_dif_sim)\n",
    "\n",
    "corr_hp_gdpt_pi = corr(hp_gdpt_sim, hp_pi_sim)\n",
    "\n",
    "corr_hp_gdpt_exchange = corr(hp_gdpt_sim, hp_exchange_sim)\n",
    "\n",
    "corr_hp_gdpt_tby = corr(hp_gdpt_sim, hp_trade_bal_sim)\n",
    "\n",
    "corr_hp_gdpt_LC_yield = corr(hp_gdpt_sim, hp_LC_yield_sim)\n",
    "\n",
    "corr_hp_gdpt_LC_spread = corr(hp_gdpt_sim, hp_LC_spread_sim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0124a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "#  Store moments in dictionary\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "moments = {\n",
    "    # Averages\n",
    "    'av_externaldebt_gdp': av_externaldebt_gdp,\n",
    "    'av_share_LC': av_share_LC,\n",
    "    'av_pi': av_pi,\n",
    "    'av_LC_yield_sim': av_LC_yield_sim,\n",
    "    'av_LC_spread_sim':av_LC_spread_sim,\n",
    "    \n",
    "    # Standard deviations (levels)\n",
    "    'sd_externaldebt_gdp': sd_externaldebt_gdp,\n",
    "    'sd_share_LC_rat': sd_share_LC_rat,\n",
    "    'sd_share_LC_dif': sd_share_LC_dif,\n",
    "    'sd_pi': sd_pi,\n",
    "    'sd_exchange_rate': sd_exchange_rate,\n",
    "    'sd_yt': sd_yt,\n",
    "    'sd_gdpr': sd_gdpr,\n",
    "    'sd_gdpt': sd_gdpt,\n",
    "    'sd_LC_yield': sd_LC_yield,\n",
    "    'sd_LC_spread' : sd_LC_spread,\n",
    "    \n",
    "    # Standard deviations (HP-filtered series)\n",
    "    'sd_externaldebt_gdp_hp': sd_externaldebt_gdp_hp,\n",
    "    'sd_share_LC_rat_hp': sd_share_LC_rat_hp,\n",
    "    'sd_share_LC_dif_hp': sd_share_LC_dif_hp,\n",
    "    'sd_pi_hp': sd_pi_hp,\n",
    "    'sd_exchange_hp': sd_exchange_hp,\n",
    "    'sd_yt_hp': sd_yt_hp,\n",
    "    'sd_gdpr_hp': sd_gdpr_hp,\n",
    "    'sd_gdpt_hp' : sd_gdpt_hp,\n",
    "    'sd_tby_hp': sd_tby_hp,\n",
    "    'sd_LC_yield_hp':sd_LC_yield_hp,\n",
    "    'sd_LC_spread_hp': sd_LC_spread_hp,\n",
    "    \n",
    "    # Correlations between HP-filtered GDP and other variables\n",
    "    'corr_hp_gdp_externaldebt_gdp': corr_hp_gdp_externaldebt_gdp,\n",
    "    'corr_hp_gdp_share_LC_rat': corr_hp_gdp_share_LC_rat,\n",
    "    'corr_hp_gdp_share_LC_dif': corr_hp_gdp_share_LC_dif,\n",
    "    'corr_hp_gdp_pi': corr_hp_gdp_pi,\n",
    "    'corr_hp_gdp_exchange': corr_hp_gdp_exchange,\n",
    "    'corr_hp_gdp_tby': corr_hp_gdp_tby,\n",
    "    'corr_hp_gdp_LC_yield': corr_hp_gdp_LC_yield,\n",
    "    'corr_hp_gdp_LC_spread': corr_hp_gdp_LC_spread,\n",
    "    \n",
    "    # Correlations between HP-filtered yt and other variables\n",
    "    'corr_hp_yt_externaldebt_gdp': corr_hp_yt_externaldebt_gdp,\n",
    "    'corr_hp_yt_share_LC_rat': corr_hp_yt_share_LC_rat,\n",
    "    'corr_hp_yt_share_LC_dif': corr_hp_yt_share_LC_dif,\n",
    "    'corr_hp_yt_pi': corr_hp_yt_pi,\n",
    "    'corr_hp_yt_exchange': corr_hp_yt_exchange,\n",
    "    'corr_hp_yt_tby': corr_hp_yt_tby,\n",
    "    'corr_hp_yt_LC_yield' : corr_hp_yt_LC_yield,\n",
    "    'corr_hp_yt_LC_spread': corr_hp_yt_LC_spread\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7aff45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "moments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b411d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = Path(path or \".\").expanduser().resolve()\n",
    "outfile = base / \"moments.json\"\n",
    "outfile.write_text(json.dumps(moments, indent=2, sort_keys=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "enviro_dis",
   "language": "python",
   "name": "enviro_dis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
